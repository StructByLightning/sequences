import Chapter from "@/components/Chapter/Chapter";
import Latex from "@/components/Latex/Latex";

export default function AbsenceOfEvidence() {
  return <Chapter title={["Absence of Evidence", "Is Evidence of Absence"]}>
    <p>From Robyn Dawes's <em>Rational Choice in an Uncertain World</em>:<span className="footnote">Robyn M. Dawes, <em>Rational Choice in An Uncertain World</em>, 1st ed., ed. Jerome Kagan (San Diego, CA: Harcourt Brace Jovanovich, 1988), 250-251.</span></p>
    <blockquote>
      <p>In fact, this post-hoc fitting of evidence to hypothesis was involved in a most grievous chapter in United States history: the internment of Japanese-Americans at the beginning of the Second World War. When California governor Earl Warren testified before a congressional hearing in San Francisco on February 21, 1942, a questioner pointed out that there had been no sabotage or any other type of espionage by the Japanese-Americans up to that time. Warren responded, "I take the view that this lack [of subversive activity] is the most ominous sign in our whole situation. It convinces me more than perhaps any other factor that the sabotage we are to get, the Fifth Column activities are to get, are timed just like Pearl Harbor was timed . . . I believe we are just being lulled into a false sense of security."</p>
    </blockquote>
    <p><span className="dropCap">C</span>onsider Warren's argument from a Bayesian perspective. When we see evidence, hypotheses that assigned a <em>higher</em> likelihood to that evidence gain probability at the expense of hypotheses that assigned a <em>lower</em> likelihood to the evidence. This is a phenomenon of <em>relative</em> likelihoods and <em>relative</em> probabilities. You can assign a high likelihood to the evidence and still lose probability mass to some other hypothesis, if that other hypothesis assigns a likelihood that is even higher.</p>
    <p>Warren seems to be arguing that, given that we see no sabotage, this <em>confirms</em> that a Fifth Column exists. You could argue that a Fifth Column <em>might</em> delay its sabotage. But the likelihood is still higher that the <em>absence</em> of a Fifth Column would perform an absence of sabotage.</p>
    <p>Let <Latex math="E" /> stand for the observation of sabotage, and <Latex math="\neg E" /> for the observation of no sabotage. The symbol <Latex math="H_1" /> stands for the hypothesis of a Japanese-American Fifth Column, and <Latex math="H_2" /> for the hypothesis that no Fifth Column exists. The <em>conditional probability</em> <Latex math="P(E|H)" />, or "<Latex math="E" /> given <Latex math="H" />," is how confidently we'd expect to see the evidence <Latex math="E" /> if we assumed the hypothesis <Latex math="H" /> were true.</p>
    <p>Whatever the likelihood that a Fifth Column would do no sabotage, the probability <Latex math="P(\neg E|H_1)" />, it won't be as large as the likelihood that there's no sabotage <em>given that there's no Fifth Column</em>, the probability <Latex math="P(\neg E|H_2)" />. So observing a lack of sabotage increases the probability that no Fifth Column exists.</p>
    <p>A lack of sabotage doesn't <em>prove</em> that no Fifth Column exists. Absence of <em>proof</em> is not <em>proof</em> of absence. In logic, <Latex math="(A \Rightarrow B)" />, read "<Latex math="A" /> implies <Latex math="B" />," is not equivalent to <Latex math="(\neg A \Rightarrow \neg B)" />, read "not-<Latex math="A" /> implies not-<Latex math="B" />."</p>
    <p>But in probability theory, absence of <em>evidence</em> is always <em>evidence</em> of absence. If <Latex math="E" /> is a binary event and <Latex math="P(H|E) > P(H)" />, i.e., seeing <Latex math="E" /> increases the probability of <Latex math="H" />, then <Latex math="P(H|\neg E) < P(H)" />, i.e., failure to observe <Latex math="E" /> decreases the probability of <Latex math="H" />. The probability <Latex math="P(H)" /> is a weighted mix of <Latex math="P(H|E)" /> and <Latex math="P(H|\neg E)" />, and necessarily lies between the two. If any of this sounds at all confusing, see <em>An Intuitive Explanation of Bayes's Theorem</em>.</p>
    <p>Under the vast majority of real-life circumstances, a cause may not reliably produce signs of itself, but the absence of the cause is even less likely to produce the signs. The absence of an observation may be strong evidence of absence or very weak evidence of absence, depending on how likely the cause is to produce the observation. The absence of an observation that is only weakly permitted (even if the alternative hypothesis does not allow it at all) is very weak evidence of absence (though it is evidence nonetheless). This is the fallacy of "gaps in the fossil record"â€”fossils form only rarely; it is futile to trumpet the absence of a weakly permitted observation when many strong positive observations have already been recorded. But if there are <em>no</em> positive observations at all, it is time to worry; hence the Fermi Paradox.</p>
    <p>Your strength as a rationalist is your ability to be more confused by fiction than by reality; if you are equally good at explaining any outcome you have zero knowledge. The strength of a model is not what it <em>can</em> explain, but what it <em>can't</em>, for only prohibitions constrain anticipation. If you don't notice when your model makes the evidence unlikely, you might as well have no model, and also you might as well have no evidence; no brain and no eyes.</p>
    <p></p>
  </Chapter>
}