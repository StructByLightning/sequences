import React from "react";
import Chapter from "@/components/Chapter/Chapter";

export default function TheBottomLine() {
  return <Chapter title={["The Bottom Line"]}>


    <p><span className="dropCap">T</span>here are two sealed boxes up for auction, box <em>A</em> and box <em>B</em>. One and only one of these boxes contains a valuable diamond. There are all manner of signs and portents indicating whether a box contains a diamond; but I have no sign which I <em>know</em> to be perfectly reliable. There is a blue stamp on one box, for example, and I know that boxes which contain diamonds are more likely than empty boxes to show a blue stamp. Or one box has a shiny surface, and I have a suspicion—I am not sure—that no diamond-containing box is ever shiny.</p>
    <p>Now suppose there is a clever arguer, holding a sheet of paper, and they say to the owners of box <em>A</em> and box <em>B</em>: “Bid for my services, and whoever wins my services, I shall argue that their box contains the diamond, so that the box will receive a higher price.” So the box-owners bid, and box <em>B</em>’s owner bids higher, winning the services of the clever arguer.</p>
    <p>The clever arguer begins to organize their thoughts. First, they write, “And <em>therefore</em>, box <em>B</em> contains the diamond!” at the bottom of their sheet of paper. Then, at the top of the paper, the clever arguer writes, “Box <em>B</em> shows a blue stamp,” and beneath it, “Box <em>A</em> is shiny,” and then, “Box <em>B</em> is lighter than box <em>A</em>,” and so on through many signs and portents; yet the clever arguer neglects all those signs which might argue in favor of box <em>A</em>. And then the clever arguer comes to me and recites from their sheet of paper: “Box <em>B</em> shows a blue stamp, and box <em>A</em> is shiny,” and so on, until they reach: “and <em>therefore</em>, box B contains the diamond.”</p>
    <p>But consider: At the moment when the clever arguer wrote down their conclusion, at the moment they put ink on their sheet of paper, the evidential entanglement of that physical ink with the physical boxes became fixed.</p>
    <p>It may help to visualize a collection of worlds—Everett branches or Tegmark duplicates—within which there is some objective frequency at which box <em>A</em> or box <em>B</em> contains a diamond. There’s likewise some objective frequency within the subset “worlds with a shiny box <em>A</em>” where box <em>B</em> contains the diamond; and some objective frequency in “worlds with shiny box <em>A</em> and blue-stamped box <em>B</em>” where box <em>B</em> contains the diamond.</p>
    <p>The ink on paper is formed into odd shapes and curves, which look like this text: “And <em>therefore</em>, box <em>B</em> contains the diamond.” If you happened to be a literate English speaker, you might become confused, and think that this shaped ink somehow <em>meant</em> that box <em>B</em> contained the diamond. Subjects instructed to say the color of printed pictures and shown the picture Green often say “green” instead of “red.” It helps to be illiterate, so that you are not confused by the shape of the ink.</p>
    <p>To us, the true import of a thing is its entanglement with other things. Consider again the collection of worlds, Everett branches or Tegmark duplicates. At the moment when all clever arguers in all worlds put ink to the bottom line of their paper—let us suppose this is a single moment—it fixed the correlation of the ink with the boxes. The clever arguer writes in non-erasable pen; the ink will not change. The boxes will not change. Within the subset of worlds where the ink says “And therefore, box <em>B</em> contains the diamond,” there is already some fixed percentage of worlds where box <em>A</em> contains the diamond. This will not change regardless of what is written in on the blank lines above.</p>
    <p>So the evidential entanglement of the ink is fixed, and I leave to you to decide what it might be. Perhaps box owners who believe a better case can be made for them are more liable to hire advertisers; perhaps box owners who fear their own deficiencies bid higher. If the box owners do not themselves understand the signs and portents, then the ink will be completely unentangled with the boxes’ contents, though it may tell you something about the owners’ finances and bidding habits.</p>
    <p>Now suppose another person present is genuinely curious, and they <em>first</em> write down all the distinguishing signs of <em>both</em> boxes on a sheet of paper, and then apply their knowledge and the laws of probability and write down at the bottom: “<em>Therefore</em>, I estimate an 85% probability that box <em>B</em> contains the diamond.” Of what is this handwriting evidence? Examining the chain of cause and effect leading to this physical ink on physical paper, I find that the chain of causality wends its way through all the signs and portents of the boxes, and is dependent on these signs; for in worlds with different portents, a different probability is written at the bottom.</p>
    <p>So the handwriting of the curious inquirer is entangled with the signs and portents and the contents of the boxes, whereas the handwriting of the clever arguer is evidence only of which owner paid the higher bid. There is a great difference in the indications of ink, though one who foolishly read aloud the ink-shapes might think the English words sounded similar.</p>
    <p>Your effectiveness as a rationalist is determined by whichever algorithm actually writes the bottom line of your thoughts. If your car makes metallic squealing noises when you brake, and you aren’t willing to face up to the financial cost of getting your brakes replaced, you can decide to look for reasons why your car might not need fixing. But the actual percentage of you that survive in Everett branches or Tegmark worlds—which we will take to describe your effectiveness as a rationalist—is determined by the algorithm that decided <em>which</em> conclusion you would seek arguments for. In this case, the real algorithm is “Never repair anything expensive.” If this is a good algorithm, fine; if this is a bad algorithm, oh well. The arguments you write afterward, above the bottom line, will not change anything either way.</p>
    <p>This is intended as a caution for your own thinking, not a Fully General Counterargument against conclusions you don’t like. For it is indeed a clever argument to say “My opponent is a clever arguer,” if you are paying yourself to retain whatever beliefs you had at the start. The world’s cleverest arguer may point out that the Sun is shining, and yet it is still probably daytime.</p>
  </Chapter>;
}